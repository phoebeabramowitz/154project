---
title: "Data Cleaning Exploration"
author: "Phoebe Abramowitz"
date: "3/4/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
```

Upload Files:
```{r}
setwd("~/Desktop/Berkeley/Spring19/stat_154/154project")
#source("./data_cleaning .R")
```

Network retrieved data until the end but sometimes the connection failed, logger has data from when the connection failed but not always until the end

```{r}
#Ask how to read this, or manually change the format into something I can read with delim then cut 
#datetime <- read.delim("./data/sonoma-dates", header=FALSE)
```
Temperature:
```{r}
library(ggplot2)
library(dplyr)
library(GGally)
#why are min & max NA? Doesnt matter becuase summary accurately gives min and max
range(data_net$humid_temp)
range(data_log$humid_temp)
#similar mean and median, exist in same reasonable scale except outliers
summary(data_net$humid_temp)
summary(data_log$humid_temp)
ggplot(data_net, aes(x=humid_temp)) + geom_histogram()
ggplot(data_log, aes(x=humid_temp)) + geom_histogram()
```
Relative Humidity:
```{r}
range(data_net$humidity)
range(data_log$humidity)
summary(data_net$humidity)
#Same Scale just with crazy lower outlier
summary(data_log$humidity)
ggplot(data_net, aes(x=humidity)) + geom_histogram()
ggplot(data_log, aes(x=humidity)) + geom_histogram()
```
```

Incident PAR:hamatop? 
```{r}
# > half zero, implies PAR becuase was done before the solstice so usually no sun
summary(data_net$hamatop)
#massive outlier(s) on the max in log
summary(data_log$hamatop)

#ONLY RUN THIS ONCE, following link 
data_net$hamatop <- data_net$hamatop*0.0185
data_net$hamabot <- data_net$hamabot*0.0185
data_log$hamatop <- data_log$hamatop*0.0185
data_log$hamabot <- data_log$hamabot*0.0185

#before modifying the range 
data_log <- filter(data_log, hamatop < 10*quantile(data_log$hamatop, na.rm=TRUE)[4])
ggplot(data_net) + 
  geom_histogram(aes(x=hamatop),color="darkblue", fill="lightblue",binwidth=20)+
  ggtitle("Net Incident PAR")+
  theme_minimal()
ggplot(data_log) + 
  geom_histogram(aes(x=hamatop),color="darkblue", fill="lightblue",binwidth=20)+
  ggtitle("Log Incident PAR")+
  theme_minimal()

```
Reflective PAR:check column use here?
```{r}
range(data_net$hamabot)
range(data_log$hamabot)
summary(data_net$hamabot)
#massive outlier(s) on the max in log
summary(data_log$hamabot)

ggplot(data_net) + 
  geom_histogram(aes(x=hamabot),color="darkblue", fill="lightblue",binwidth=6)+
  ggtitle("Net Reflected PAR")+
  theme_minimal()
ggplot(data_log) + 
  geom_histogram(aes(x=hamabot),color="darkblue", fill="lightblue",binwidth=6)+
  ggtitle("Log Reflected PAR")+
  theme_minimal()
```
Voltage-measure of Battery:
```{r}
range(data_net$voltage)-range(data_log$voltage)
#voltage is clearly different scales between log and net
#log data matches the paper
#convert net data to match the paper
ggplot(data_net) + 
  geom_histogram(aes(x=voltage),color="darkblue", fill="lightblue",binwidth=10)+
  ggtitle("Net Unconverted Voltage")+
  theme_minimal()
ggplot(data_log) + 
  geom_histogram(aes(x=voltage),color="darkblue", fill="lightblue",binwidth=0.2)+
  ggtitle("Log Voltage")+
  theme_minimal()

test <- data_net %>%
  mutate("converted_voltage" = data_net$voltage*12.33 / 1023)

data_net$voltage = data_net$voltage*12.33 / 1023
summary(data_net$voltage)
summary(test$converted_voltage)
```
epoch, nodeid, result_time-Distinguishing between points
```{r}
#range of epoch is very inconsistant, why?
range(data_net$epoch)-range(data_log$epoch)
summary(data_log$epoch)
summary(data_net$epoch)

#Why does nodeid go so high in log?-Just one nodeid is extremely wrong. Look at that Data point
summary(data_log$nodeid)
#manually take out single outlier, shows nothign else is above 200, which is correct
data_log <- filter(data_log, nodeid<60000)
#inconsistant number of instances per node in both net and log 
ggplot(data_log_ex, aes(x=nodeid)) + geom_histogram(bindwidth=5)
ggplot(data_net, aes(x=nodeid)) + geom_histogram(bindwidth=5)

summary(data_log_ex$nodeid)
summary(data_net$nodeid) #without outlier in log, they're similar ranges and scales
ggplot(data_net, aes(x=nodeid)) + geom_histogram(binwidth=5)
```
Choose to combine net and log Either can work to become the "Main Table"
```{r}
#First need to equate ranges, as above

#concatenate everything in data_net with everything in data_log that isn't in data_net, defined by epoch and nodeid
library(dplyr)
data_log$result_time
just_log <- anti_join(data_log, data_net, by = c("nodeid" = "nodeid", "epoch" = "epoch"))
#what to do about the essentially lack of result_time in data_log
<<<<<<< HEAD
all_readings <- full_join(data_net, just_log)
all_readings <- all_readings[,1:11]
=======
data_main <- full_join(data_net, just_log)
#shouldnt need this step 
data_main <- data_main[,1:11]
>>>>>>> c2810cee2a4c063294ec4754b08a2111ee4072ad
```

```{r}
# trying to reconcile the duplicate values of nodeid and epoch
# first I selected only the columns of interest and renamed them
# Then I cast the result_time column as a date + time object in R so we can work with it.. 
# remove one outlier..

df <- all_readings %>%
  select(c("result_time", "epoch", "nodeid", "voltage", "humid_temp", "humid_adj", "hamatop", "hamabot")) %>%
  rename(temp = humid_temp) %>%
  rename(humid = humid_adj) %>%
  rename(incident_PAR = hamatop) %>%
  rename(reflect_PAR = hamabot) %>%
  mutate(result_time = as.POSIXct(result_time))

  # group_by(nodeid, epoch) %>%
  # summarise(parent = mean(parent)) %>%
  # summarise(voltage = mean(voltage)) %>%
  # summarise(depth = mean(depth)) %>%
  # summarise(humidity = mean(humidity)) %>%
  # summarise(humid_temp = mean(humid_temp)) %>%
  # summarise(humid_adj = mean(humid_adj)) %>%
  # summarise(hamatop = mean(hamatop)) %>%
  # summarise(hamabot = mean(hamabot)) %>%
  # select(c("parent", "voltage", "depth", "humidity", "humid_temp", "humid_adj", "hamatop", "hamabot"))
```

```{r}
# My idea here was to group by id and epoch, and then take average across all other columns, but i dont know if this is a good idea anymore given the graph i plotted. Also im still not sure how to do this type of grouping in R..

# df %>%
# group_by(nodeid, epoch) %>%
# summarise(result_time = mean(result_time)) 
  # summarise(voltage = mean(voltage)) %>%
  # summarise(humid = mean(humid)) %>%
  # summarise(incident_PAR = mean(incident_PAR)) %>%
  # summarise(reflect_PAR = mean(reflect_PAR)) %>%
  # summarise(temperature = mean(temperature))
```


```{r}
sample_data <- data_net[sample(1:114980, 2000),]
ggplot(sample_data) + geom_point(aes(x=epoch, y=result_time))
```

```{r}
ggplot(df) + geom_point(aes(x=epoch, y=result_time))
```

```{r}
mote_location <- mote_location %>%
  rename(nodeid = ID)

main <- left_join(df, mote_location) %>%
  rename(height = Height) %>%
  rename(direc = Direc) %>%
  rename(dist = Dist) %>%
  rename(tree = Tree)
#337743 observations of 12 variables
```

```{r}
# the radial distance should be between 0-1 meter, the original dataset had some distances of up to 5 meters... should we remove them?
ggplot(main %>% filter(dist <= 1)) + geom_point(aes(x=dist, y=height))
```

```{r}
# getting rid of bad temperature readings.. using the temp range from the paper
ggplot(main %>% filter(temp > 6 & temp < 33 )) + geom_point(aes(x=result_time, y=temp))
```

```{r}
# looks similarish to the histogram in the paper, after removing outliers and fault readings
temp_test <- main %>% filter(temp > 6 & temp < 33 )
hist(temp_test$temp)
```

```{r}
ggplot(main) + geom_point(aes(x=nodeid, y=voltage))
```
```{r}
ggplot(main %>% filter(voltage >= 2.4 & voltage <= 3)) + geom_point(aes(x=result_time, y=voltage))
```

```{r}
# im only going to remove entries with fault voltage readings, and see if that's enough for outlier detection..

good_volt <- main %>%
  filter(voltage >= 2.4 & voltage <= 3)
# removes 35,886 rows..

```

```{r}
good_volt %>% 
  filter(epoch < 2000)
```


ANSWERED We chose adjusted humidity becuase it matches the max in the report, and it's importatn to adjust for teemp

Are all the missing values NA? 
  When should zero values be NAs?

ANSWERED How to use the Humid adjustment column?- As humidity? YES

In log, why is epoch+nodeid is not a unique descriptor of row? Within these rows with same epoch & nodeid, there's variation between voltage, humid_temp, humidity, humid_adjust.
  What is epoch?- Sample Number
  If we group by epoch + nodeid, what happens?
  Why are there so many unique nodeids? 31 for net but 72 (extra) for log, paper says there's 33     sensors. 
  Why do numbers go up to 200? Do the numbers matter, hopefully not?

ANSWERED(for now)Voltage Conversion? 

ANSWERED check that humid_temp summary matches the paper 

ANSWEREDHamatop&hamabot- incident and reflective, respectively?   
ANWERED: hamatop and hamabot need Lux to PPFD conversion in order to be consistent with the paper. 
 Lux to PPFD(Âµmol m-2 s-1, used in the paper): 0.0185
 Lux of full sunlight is 108,000, consistant with the maximum numbers in 

We're choosing to combine then deal with most outliers: justify this

<<<<<<< HEAD
_____________________________________
Voltage:
range for data_net is 198-1023
range for data_log is 0.009 - 3.03
range for data_all is 0.009 - 1023
Maybe because the log is a physical node located at the redwood tree, while the net data was transferred through the GPRS? (prob not but I asked my bro)

ATmega128 has a 10-bit ADC operating on 4.5 - 5.5V (http://ww1.microchip.com/downloads/en/DeviceDoc/doc2467.pdf)

5V is assumed to be 1023, use the following equation of ratios for the conversion.
(https://learn.sparkfun.com/tutorials/analog-to-digital-conversion/relating-adc-value-to-voltage)

1023/5 = ADC reading/analog voltage measured

I think ADC reading is the voltage value in data_net, and 'analog voltage measured is' what we want to convert to

Hence the formula we should use to convert data_net voltage is as follows:
x = (5*data_net reading) / 1023
```{r}
test <- data_net %>%
  mutate("converted_voltage" = data_net$voltage*12.33 / 1023) %>%
  select(c("voltage", "converted_voltage"))

summary(test$converted_voltage)
summary(data_log$voltage)

```

________________________________________
result time in data log are all exactly the same. There are different node IDs and epochs across the nodeid's, but there are some repeats with slight variation in humidity or temp or depth.. wtf is going on? 

```{r}

length(unique(data_net$nodeid))

length(unique(data_log$nodeid))

data_main <- good_volt
```


Choosing to deal with duplicate epoch nodeid after joining

