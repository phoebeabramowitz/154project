---
title: "Project 1 Redwood Data Report"
author: "Phoebe Abramowitz(26386343) & Omri Newman(3032273024)"
output:
  pdf_document: default
date: "3/8/2019"
---

```{r, include=FALSE}
knitr::opts_chunk$set(include=TRUE,echo = FALSE, message = FALSE, warning = FALSE, eval=TRUE,
                      fig.width=3, fig.height=3, fig.align='center',
                      fig.asp = 1
                      )
library(tidyverse)
library(GGally)
library(dplyr)
library(ggplot2)
library(lubridate)
```
#Paper Summary (20 pts)

  This study of microclimatic monitoring aims to get a better understanding of the life of a Redwood tree in Sonoma, CA. To do this, an interdisciplinary team from the University of California, Berkeley designed an experiment that paints a picture of a redwood tree’s ecophysiology spanning fourty-four days in Spring 2004. They did this using a unique network of nodes and wireless sensors to gather spatio-temporal and environmental dynamic data over the entire organism. Each of the thirty-three nodes collected hundreds of thousands of data points, which lie in four different three-dimensional spaces (time x height x value). This wireless sensor network, or macroscope, allows for rich analysis on an unprecedented dataset.  
  After brainstorming with several biologists, Sonoma’s coastal redwood forest was chosen as the site of this study because of its dynamic ecosystem. Longer daylight hours during the Spring provided sufficient time for the photosynthetically active radiation sensors to collect data, and the coastal fog coming off the Pacific guaranteed a wide range of temperature and humidity gradients.  
  A thorough analysis of the redwood data confirmed the biologists’ hypothesis, which premised the existence of dynamic gradients present in the redwood trees ecophysiology. By projecting the data points onto a subset of the three-dimensions, the analysis task became simpler.  
  One drawback to using the sensor network was the presence of missing values throughout the data set in both time and height dimensions. However, the team worked in spite of this by studying distributions in most of their analyses.  In addition to confirming the team’s hypothesis, more information about the climatic distribution of the tree was extracted from the analysis. One impactful step was using the data to build a quantitative model of the effect of microclimatic gradients on the sap flow rate of redwood trees. By better understanding this process, biologists can piece together a more detailed picture of the larger scale carbon and water exchange within a forest ecosystem.  
  The main variables of interest in this study are those that shed light on the microclimate and ecophysiology of the redwood tree. Thus, each data point can be viewed in three dimensions-- time, height, and value. The values, recorded by the network of sensors, are temperature, humidity, incident photosynthetically active solar radiation (PAR), and reflected PAR. Collecting this data over an extended period of time required a powerful system and precise deployment methodology. The data collection time period started in late April and spanned fourty-four days, sampling all sensors every five minutes. The nodes were placed along the seventy meter redwood tree starting at a height of fifteen meters, with two-meter spacing between nodes. The west side of the tree had a thicker canopy that served as protection against environmental effects, so the majority of the nodes were placed there. Lastly, the nodes were placed close to the trunk (0.1-1.0 meter) such that the recordings were of the microclimatic trends of the tree and not the wider climate.  
  Multiple sensors were integrated into the Mica2Dot wireless node, as a means to gather data on the environmental dynamics of the tree. This node has a one inch diameter form factor, an Atmel microcontroller running at 4 MHz, a 433 MHz radio from Chipcon operating at 40Kbps, and 512kB of flash memory. The node was packaged into a sealed cylindrical enclosure made from white high-density polyethylene that reflects radiated heat. The enclosure contained the node, battery, and two sensor boards - one for direct radiation and one for all other measurements. Data collected from these nodes were stored in a local database or gateway, then transmitted to an offsite database via a general packet radio service (GPRS) cellular modem. The UCB team used TASK software as the node operating system and data collection scheme to aid with this work. This multi-hop system utilized TinyOS and MintRoute systems to retrieve data from the nodes and store them in the gateway as efficiently as possible. The entire network of nodes was awake for four seconds every five minutes, in order to take sensor readings, transfer the data to the base stations, and then return to sleep.  
  Two calibration schemes were completed by the team to ensure a satisfactory operation prior to setting up the final system. The first calibration consisted of leaving the sensors on a roof collecting PAR data every thirty second for two weeks to verify the accuracy of the readings. The purpose of the second calibration was to understand the response of the temperature and humidity sensors. The nodes were tested in a controllable weather chamber that had varying temperature and humidity conditions, and recorded readings every thirty seconds. The calibration techniques used on the nodes took up space on the 512kB flash memory. Thus, some of the data loggers in the local database gateway ran out of memory before the end of the data collection time period. These loggers were meant to serve as a backup in case of network failure, and stored data in the case of lost GPRS connectivity. On the other hand, the logger data that was stored in the gateway could only be accessed at the end of the data collection time period, and there was lost information in the nodes that ran out of flash memory. This defines the main difference between sonoma-data-net.csv and sonoma-data-log.csv, which both contain values the other is missing.  

***

#Data cleaning (40 pts)
  
This data set contains gross outliers, inconsistencies, and lots of missing values. We use basic exploratory data analysis and data cleaning techniques to get a better understanding of the data, determine which values make sense in the context of the study, and remove missing values when necessary.


1. For the initial comparison in hamatop (Incident PAR) between **sonoma-data-log.csv** and **sonoma-data-net.csv**, we remove outliers that are ten times larger than the third quartile in an effort to explore the ranges more thoroughly. We notice a slight bump in the right tail of incident PARs histogram for **sonoma-data-net.csv**, which does not occur in **sonoma-data-log.csv**.
```{r, echo=FALSE,eval=TRUE}
# Make sure working directory is project directory which contains /data with all files
#For Phoebe setwd("~/Desktop/Berkeley/Spring19/stat_154/154project")
# For Omri setwd("~/Stat 154/Project 1/Proj1")

#location data
mote_location <- read.delim("./data/mote-location-data.txt", sep="")

#datetime
datetime <- read.csv("./data/sonoma-dates", header=FALSE)

#data retrieved from the flash logs
data_log <- read.csv("./data/sonoma-data-log.csv")

#data retrieved over the wireless network
data_net <- read.csv("./data/sonoma-data-net.csv")

#simply concatenated
data_all <- read.csv("./data/sonoma-data-all.csv")
# Incident PAR histograms

#remove an outlier
data_log <- filter(data_log, hamatop < 10*quantile(data_log$hamatop, na.rm=TRUE)[4])

ggplot(data_net) +
  geom_histogram(aes(x=hamatop),color="darkblue", fill="lightblue",binwidth=20)+
  ggtitle("Net Incident PAR")+
  theme_minimal()
ggplot(data_log) +
  geom_histogram(aes(x=hamatop),color="darkblue", fill="lightblue",binwidth=20)+
  ggtitle("Log Incident PAR")+
  theme_minimal()
```

The histograms for hamabot (Reflected PAR) reveal some interesting trends shared by *** sonoma-data-log.csv** and **sonoma-data-net.csv**. Not only are their ranges the same, but they both exhibit the same gaps in the values of hamabot that occur.
```{r, echo=FALSE}
# Reflected PAR histograms
ggplot(data_net) +
  geom_histogram(aes(x=hamabot),color="darkblue", fill="lightblue",binwidth=6)+
  ggtitle("Net Reflected PAR")+
  theme_minimal()
ggplot(data_log) +
  geom_histogram(aes(x=hamabot),color="darkblue", fill="lightblue",binwidth=6)+
  ggtitle("Log Reflected PAR")+
  theme_minimal()
```

It is clear from the histograms below that voltage readings are not consistent between **sonoma-data-log.csv** and **sonoma-data-net.csv**
```{r, echo=FALSE}
# Voltage histograms
ggplot(data_net) +
  geom_histogram(aes(x=voltage),color="darkblue", fill="lightblue",binwidth=10)+
  ggtitle("Net Unconverted Voltage")+
  theme_minimal()
ggplot(data_log) +
  geom_histogram(aes(x=voltage),color="darkblue", fill="lightblue",binwidth=0.2)+
  ggtitle("Log Voltage")+
  theme_minimal()
```

To reconcile the inconsistencies between voltage and PAR, we applied two separate conversions as to match the ranges from the paper:  
The voltage readings in **sonoma-data-log.csv** are generally within the correct range of just a few volts, while the readings in **sonoma-data-net.csv** had significantly higher values. This discrepancy can be attributed to the analog-to-digital converter used within the ATmega128 node^1^. To switch from the 10-bit ADC readings to actual voltage measured, we followed a simple ratiometric conversion scheme ^2^. We multiplied the values by 12.33 and divided by 1023 to transform the data into the desired range.

We also noticed the ranges for hamatop and hamabot differ from the paper. We convert the measurements of both types of PAR from Lux to PPMG, the units expressed in the visualizations in the study, using a 0.0185 conversion factor.
```{r, include=FALSE, echo=FALSE}
# ONLY RUN THIS ONCE!!!

#Incident and Reflected PAR
data_net$hamatop <- data_net$hamatop*0.0185
data_net$hamabot <- data_net$hamabot*0.0185
data_log$hamatop <- data_log$hamatop*0.0185
data_log$hamabot <- data_log$hamabot*0.0185

# Voltage
data_net$voltage = data_net$voltage*12.33 / 1023
```
We then combine data sets from the log and the network into one main data set. We take the values from the network dataset in cases of dual instances, as the times are more precise. 
```{r, include=FALSE}
# Concatenate everything in data_net with everything in data_log
# that isn't in data_net, defined by epoch and nodeid
just_log <- anti_join(data_log, data_net, by = c("nodeid" = "nodeid", "epoch" = "epoch"))
all_readings <- full_join(data_net, just_log)
# to combat different error all_readings <- all_readings[,1:11]

# Cleaning all_readings before adding mote_location
df <- all_readings %>%
  select(c("result_time", "epoch", "nodeid", "voltage", "humid_temp", "humid_adj", "hamatop", "hamabot")) %>%
  rename(temp = humid_temp) %>%
  rename(humid = humid_adj) %>%
  rename(incident_PAR = hamatop) %>%
  rename(reflect_PAR = hamabot) %>%
  mutate(result_time = as.POSIXct(result_time))
```

In our main data table, we remove 3686 rows where the temperature, humidity, reflective PAR, and incident PAR are missing. There are 3686 values missing for each of the 4 variables.
```{r, include=FALSE}
#Number of missing values for each variable(don't display this)
sum(is.na(df$temp))
sum(is.na(df$humid))
sum(is.na(df$incident_PAR))
sum(is.na(df$reflect_PAR))
#Initial Number of rows missing any measurements
na_vals <- df %>% filter(is.na(temp)) %>% filter(is.na(humid)) %>%
  filter(is.na(incident_PAR)) %>% filter(is.na(reflect_PAR))
#Remove missing Data rows
df <- df %>% filter(!is.na(temp)) %>% filter(!is.na(humid)) %>%
  filter(!is.na(incident_PAR)) %>% filter(!is.na(reflect_PAR))


```


After removing missing data, reconciling inconsistencies, and joining the **sonoma-data-log.csv** and **sonoma-data-net.csv**, we incorporate the **mote-location-data.txt** using nodeid as a unique identifier for each sensor. All together we have the location of each mote, along with the respective sensor data. We selected only the variables of interest amongst the 11 to create a desired dataset of all the readings. Our main table has 337,744 observations and 12 variables.


After removing missing data, reconciling inconsistencies, and joining the **sonoma-data-log.csv** and **sonoma-data-net.csv**, we incorporate the **mote-location-data.txt** using nodeid as a unique identifier for each sensor. All together we have the location of each mote within the two trees, along with the respective sensor data. We selected only the variables of interest amongst the 11 to create a desired dataset of all the readings. Our main table has 337,744 observations and 12 variables.

```{r, include=FALSE}
# Incorporate mote_location into all_readings
mote_location <- mote_location %>%
  rename(nodeid = ID)
main <- left_join(df, mote_location) %>%
  rename(height = Height) %>%
  rename(direc = Direc) %>%
  rename(dist = Dist) %>%
  rename(tree = Tree)

#337743 observations of 12 variables
```

We chose to match the range of each variable as they are presented in the paper. It is clear in the following histograms that all of the variables contain some outliers. Instead of removing these data points per variable, we noticed that filtering out rows with faulty voltage readings--which are not reliable, as detailed in the paper-- does the same job in one fell swoop. Just as is described in the paper, filtering out readings below 2.4V or above 3V removes 33,833 observations.
```{r, echo=FALSE}
# use histograms and quantiles on main, to show outliers. data_main below gets rid of faulty voltage readings..
ggplot(main) +
  geom_histogram(aes(x=voltage),color="darkblue", fill="lightblue",binwidth=1)+
  ggtitle("Voltage")+
  theme_minimal()

ggplot(main) +
  geom_histogram(aes(x=temp),color="darkblue", fill="lightblue",binwidth=4)+
  ggtitle("Temperature")+
  theme_minimal()

ggplot(main) +
  geom_histogram(aes(x=humid),color="darkblue", fill="lightblue",binwidth=4)+
  ggtitle("Humidity")+
  theme_minimal()
data_main <- main %>%
  filter(voltage >= 2.4 & voltage <= 3)
# removes 33,833 rows
```


###(Bonus) Discuss other possible outliers and explain your reason why it is better to remove them than to keep them.


#Data Exploration (40 pts)

* We choose the subset of the data occuring during the week of May 23rd through May 30th. There are more hours of sunlight in the last week of May as the summer solstice gets closer. This subset--containing ~28,000 values-- in particular has fewer missing values than other time periods, as shown in the histogram. 

```{r}
ggplot(data_main %>% filter(result_time <= as.Date("2004-11-10"))) +
  geom_histogram(aes(x=result_time), color="violet",fill="darkblue", binwidth=100)+
  ggtitle("Occurences of Data Values Over Time")+
  theme_minimal()

data_sub <- data_main %>% 
  filter(result_time >= as.Date("2004-05-23") & result_time <= as.Date("2004-05-30"))
```
###Some pairwise scatterplots of some variables and descriptions of our findings:
The number of the nodeid is not meaningfully correlated to height
```{r}
ggplot(data_sub)+
  geom_point(aes(x=height, y=nodeid),color="darkgoldenrod")+
  ggtitle("nodeid by height")+
  theme_minimal()
```
Humidity and Temperature by time and height
```{r}
ggplot(data_sub)+
  geom_point(aes(x=epoch, y=humid, alpha=0.3),color="firebrick2")+
  ggtitle("Humidity Over Time")+
  theme_minimal()

ggplot(data_sub)+
  geom_point(aes(x=height, y=humid, alpha=0.3),color="violet")+
  ggtitle("Humidity by Height")+
  theme_minimal()

ggplot(data_sub)+
  geom_point(aes(x=epoch, y=temp, alpha=0.2),color="orangered1")+
  ggtitle("Temperature Over Time")+
  theme_minimal()

ggplot(data_sub)+
  geom_point(aes(x=height, y=temp, alpha=0.3),color="deeppink1")+
  ggtitle("Temperature by Height")+
  theme_minimal()
```

Reflective PAR over time loosely indicates cycles of daylight, and the maximum value observed of reflective PAR increases with height. 
```{r}
ggplot(data_sub)+
  geom_point(aes(x=epoch, y=reflect_PAR, alpha=0.3),color="deeppink1")+
  ggtitle("Reflective PAR Over Time")+
  theme_minimal()

ggplot(data_sub)+
  geom_point(aes(x=height, y=reflect_PAR, alpha=0.3), color="deeppink1")+
  ggtitle("Reflective PAR by Height")+
  theme_minimal()
```

Are any of the predictors associated with Incident PAR? If so, explain the relationship.

Incident PAR is visibly cyclical over time. The relationship can be explained by the daily daylight cycle of the sun rising and setting, since Incident PAR measures direct sunlight. The second and third plots here show that certain nodes are exposed to more direct Sunlight, but not necessarily by height
```{r}
#Clearly shows daylight cycle
ggplot(data_sub)+
  geom_point(aes(x=epoch, y=incident_PAR, alpha=0.3),color="orangered1")+
  ggtitle("Incident PAR Over Time")+
  theme_minimal()

ggplot(data_sub)+
  geom_point(aes(x=height, y=incident_PAR, alpha=0.3), color="deeppink1")+
  ggtitle("Incident PAR by Height")+
  theme_minimal()

ggplot(data_sub)+
  geom_point(aes(x=nodeid, y=incident_PAR, alpha=0.3), color="deeppink1")+
  ggtitle("Incident PAR by Node")+
  theme_minimal()
```
*Next, we consider each variable in the context of it's temporal trends, with height as color cue:
( You can do it for different time scales during an hour, during a day or during the entire experiment). However, at least the plots with days as x-axis are required. As shown in the histogram below, I used epoch as the x variable for time here becuase their positive, linear relationship justifies our use of epoch as a standin for time that doesn't lose any information from data_log. We could also use result_time.
```{r}
ggplot(data_main %>% filter(result_time <= as.Date("2004-11-10"))) +
  geom_point(aes(x=result_time, y=epoch))+
  ggtitle("Linear relationship between epoch and result_time")
```
During the day, incident PAR is noteably least at the lowest height of the tree. However, there's not a height gradient throughout. Reflective PAR lacks this trait. 
```{r}
ggplot(data_sub)+
  geom_point(aes(x=epoch, y=incident_PAR, alpha=0.3,color=height))+
  ggtitle("Incident PAR Over Time")+
  theme_minimal()

ggplot(data_sub)+
  geom_point(aes(x=epoch, y=reflect_PAR, alpha=0.3,color=height))+
  ggtitle("Reflective PAR Over Time")+
  theme_minimal()
```
The lowest temperatures occur and the least height when and only when temperature is rising during the day.
```{r}
ggplot(data_sub)+
  geom_point(aes(x=epoch, y=temp, alpha=0.3,color=height))+
  ggtitle("Temperature Over Time")+
  theme_minimal()
# WHERE DOES THIS BELONG using this subsection of the data, we get an accurate reading of result_time, by replacing data_log result time with respective data_net result_time using the epoch as an identifier (we noticed epoch and result time are linearly correlated). The last week of May experiences higher levels of daylight hours as the seasons begin to shift and the summer solstice gets closer. We postulate these extended day light hours will have certain affects on the 

# using this subsection of the data, we get an accurate reading of result_time, by replacing data_log result time with respective data_net result_time using the epoch as an identifier (we noticed epoch and result time are linearly correlated). The last week of May experiences higher levels of daylight hours as the seasons begin to shift and the summer solstice gets closer. We postulate these extended day light hours will have certain affects on the 


ggplot(data_sub)+
  geom_point(aes(x=epoch, y=humid, alpha=0.3,color=height))+
  ggtitle("Humidity Over Time")+
  theme_minimal()

```



####PCA analysis 
Can this data be approximated by some low-dimensional representation?

PCA analysis & scree plot of the data:
Before running PCA on the desired subset of the data, we select five variables of interest (temperature, humidity, incident PAR, reflected PAR, height). We use Kaiser's criterion to choose principal components, of those with variances greater than one. We see out of the five eigenvalues, the first two are greater than one. The scree plot also shows that 73% of the variability in this data is encompassed by the first two principal components. For these reasons, we conclude there is a two-dimensional representation of this multi-dimensional data. 


```{r}
# PCA analysis
dat <- data_sub %>%
  select(c("temp", "humid", "incident_PAR", "reflect_PAR", "height"))

pca <- prcomp(na.omit(dat), scale. = TRUE)
summary(pca)

loadings <- pca$rotation
scores <- pca$x
eigenvalues <- pca$sdev^2
eigenvalues
sum(eigenvalues)
```
####Scree Plot
```{r}

eigs_cum = cumsum(eigenvalues) / sum(eigenvalues)
ggplot() + geom_point(aes(x = 1:length(eigenvalues), y=eigs_cum)) +
  labs(x = "Principal Component", y = "Fraction of Total Variance Explained") +
  ggtitle("Screeplot") + theme_minimal()
# use first two principal components because they both have variances greater than one (Kaiser's criterion)
```

The following scatter plots show PC1 places a high value on temperature and both PAR's, while PC2 places a high value on height. Both PC1 and PC2 place roughly the same weight on humidity. The nodes which experience high temperatures and high PAR readings will have a greater first principal component in absolute value, as is seen in the biplot. 
```{r}
# principal component scatter plots & biplot
ggplot() + 
  geom_point(aes(x = scores[, 1], y=scores[, 2], alpha=0.1)) +
   labs(x = "PC1", y = "PC2") + ggtitle("PC1 vs. PC2")

biplot(pca, scale=0)
```


Describe two interesting findings from exploratory analysis of the data and comment on these findings.
\begin{enumerate}[label=(\alph*)]
\item Finding 1.

Unsupervised learning techniques like clustering allow us to study patterns within multi-dimensional data sets. To start off, we run hierarchical clustering with complete linkage on the subset of interest, and notice that six clusters is a good starting point for this data. 

1. Finding 1.

```{r}
# hierarchical clutering on the data
hierarch <- hclust(dist(scale(dat)), method="complete")
summary(hierarch)
plot(hierarch, main="Complete Linkage", xlab="", sub="",
cex = .01)
abline(h=7, col="red")
```

We compare K-means clustering with K=6 to the hierarchical clustering that was just obtained, and make note of the differences. There are no zeros in the table below indicating that there is overlap between all clusters obtained by both K-means and hierarchical clustering. 
```{r}
# compare hierarchical clustering cut at 6 to K-means with K=6
K6 <- kmeans(na.omit(dat), 6)
km.clusters <- K6$cluster
table(km.clusters, hc.clusters[1:length(km.clusters)] )
```

In an attempt to remove noise from the data, we perform hierarchical clustering on the first two principal components, and compare them to the original clusters performed on all the data. The dendograms depict clear differences between the two. When all the data is used, the clusters end up relatively close to eachother, but when using the principal components they come from opposite ends of the plot. The table below also portrays the differences between the two clustering methods. 
```{r}
# perform hierarchical clustering on the first 2 or  principal components..
hc <- hclust(dist(scores[,1:2]))
plot(hc, main="Hier. Clustering on First 2 Principal Components", xlab="", sub="",
cex = .01)
abline(h=5, col="red")

# hierarchical clustering on the data vs on the first two principal components 
table(hc.clusters) # on the dat 
table(cutree(hc, 6)) # on the principal components 
```


2. Finding 2:
 
Another interesting finding is how little Incident and Reflective PAR(Direct and Ambien) seem to be correlated when you look at their 2 dimensional scatter plot, given that both measure energy available for photosynthesis and tell us about drivers for the carbon balance in the forest.
```{r}
ggplot(data_sub)+
  geom_point(aes(x=incident_PAR, y=reflect_PAR, alpha=0.3),color="darkgoldenrod")+
  ggtitle("Incident vs Refletive PAR")+
  theme_minimal()
```
However, looking at both over time it's clear they experience similar cycles with the daylight, with the fluctuations of incident PAR having a much greater magnitude.
```{r}
ggplot(data_sub)+
  geom_line(aes(x=result_time, y=incident_PAR, color="red"))+
  geom_line(aes(x=result_time,y=reflect_PAR, color="blue"))+
  ggtitle("Incident and Reflective PAR over Time")+
  theme_minimal()
```

3.(Bonus) Finding 3. Bonus is given only if we also find it interesting.


#Graph Critique in the paper (40 pts)}\
The overall quality of the paper by Tolle et al. is good. However, some plots are not perfect from a statistician's point of view.

* Figure 3[a] shows the distributions of sensor readings projected onto the value dimension, using a histogram. It turns out that both the incident and reflected PAR have long tail. We could not read full information from this histogram. Try to make a better plot with log transform of the data.
```{r}
# 5a.
ggplot(data_main) +
  geom_histogram(aes(x=incident_PAR),color="darkblue", fill="lightblue") +
  ggtitle("Incident PAR") +
  scale_y_sqrt() +
  theme_minimal()

ggplot(data_main) +
  geom_histogram(aes(x=reflect_PAR),color="darkblue", fill="lightblue") +
  ggtitle("Reflected PAR") +
  scale_y_sqrt() +
  theme_minimal()
```

* What message do the boxplots in Figure 3[c] and 3[d] try to convey? Do you think the plots convey the right messages? If not generate a new plot with the same data. Hint: compare to some plots in Figure 4.
```{r}
# 5b.
# What messages are figures 3c and 3d trying to convey? Do they convey the right message? If not, generate a new plot with the same data (compare to some plots in figure 4)

# They are 'projecting onto height and value dimensions' to look for spatial trends. 3c shows the distribution of all the readings taken by each sensor at each height. 
# We see a very different spatial trend in the temperature and humidity readings: nothing. Every sensor reached practically every point in the space of possible temperature and humidity readings. This suggests that the amount of variation over time overwhelmed the amount of variation over space. However, instead of just collapsing the temporal variation, we can explicitly remove it and focus more closely on the spatial trends. At every timestep, we take the mean of all the sensor readings. We can subtract the timestep mean from each sensor reading, and examine the distributions of the differences 3d
```

*item Any suggestions for improving the first two plots in Figure 4? Can you distinguish all the colors in these two plots?
*item Comment on Figure 7. Is it possible to generate a better visualization to highlight the difference between network and log data?



* 1: "10-bit Atmel Microcontroller with 128KBytes In-System Programmable Flash" http://ww1.microchip.com/downloads/en/DeviceDoc/doc2467.pdf
* 2: "Analog to Digital Conversion" https://learn.sparkfun.com/tutorials/analog-to-digital-conversion/relating-adc-value-to-voltage


